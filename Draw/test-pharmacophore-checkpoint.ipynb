{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#You can write your own classification file to use the module\n",
    "# from attention.model import StructuredSelfAttention\n",
    "# from attention.train import train,get_activation_wts,evaluate\n",
    "# from utils.pretrained_glove_embeddings import load_glove_embeddings\n",
    "# from utils.data_loader import load_data_set\n",
    "from visualization.attention_visualization import createHTML\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "import os,sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Molecule 190 failed\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    " \n",
    "filename = \"tox-test/tox21_10k_challenge_test.sdf\"\n",
    "basename = filename.split(\".\")[0]\n",
    " \n",
    "collector = []\n",
    " \n",
    "sdprovider = Chem.SDMolSupplier(filename)\n",
    " \n",
    "for i,mol in enumerate(sdprovider):\n",
    "    try:\n",
    "        moldict = {}\n",
    "        moldict['smiles'] = Chem.MolToSmiles(mol)\n",
    "        #Parse Data\n",
    "        for propname in mol.GetPropNames():\n",
    "            moldict[propname] = mol.GetProp(propname)\n",
    "        collector.append(moldict)\n",
    "    except:\n",
    "        print (\"Molecule %s failed\"%i)\n",
    "         \n",
    " \n",
    "data = pd.DataFrame(collector)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound Batch ID</th>\n",
       "      <th>Compound ID</th>\n",
       "      <th>NR-AR</th>\n",
       "      <th>NR-AR-LBD</th>\n",
       "      <th>NR-AhR</th>\n",
       "      <th>NR-Aromatase</th>\n",
       "      <th>NR-ER</th>\n",
       "      <th>NR-ER-LBD</th>\n",
       "      <th>NR-PPAR-gamma</th>\n",
       "      <th>SR-ARE</th>\n",
       "      <th>SR-ATAD5</th>\n",
       "      <th>SR-HSE</th>\n",
       "      <th>SR-MMP</th>\n",
       "      <th>SR-p53</th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCGC00261443-01</td>\n",
       "      <td>NCGC00261443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CNc1ncnc2c1ncn2[C@@H]1O[C@H](CO)C(O)[C@H]1O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCGC00261600-01</td>\n",
       "      <td>NCGC00261600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Oc1cc(O)cc(/C=C/c2ccc(O)c(O)c2)c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCGC00260926-01</td>\n",
       "      <td>NCGC00260926</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>COc1ccc2c(c[n+](C)c3c4cc5c(cc4ccc23)OCO5)c1OC....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCGC00261266-01</td>\n",
       "      <td>NCGC00261266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Br.Cc1onc(O)c1CC(N)C(=O)O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCGC00261897-01</td>\n",
       "      <td>NCGC00261897</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Nc1nc(N)c(N=O)c(OCC2CCCCC2)n1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NCGC00261559-01</td>\n",
       "      <td>NCGC00261559</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c1ccc2c(c1)CC(N1CCN(c3cccc4c3OCCO4)CC1)C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NCGC00261121-01</td>\n",
       "      <td>NCGC00261121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cl.Oc1cc2c(cc1O)C(c1ccccc1)CNCC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NCGC00261374-01</td>\n",
       "      <td>NCGC00261374</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cl.N=C(N)c1ccc(CS(=O)(=O)F)cc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NCGC00261612-01</td>\n",
       "      <td>NCGC00261612</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cl.O=C(OCCN1CCOCC1)C1(c2ccccc2)CCCCC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NCGC00261002-01</td>\n",
       "      <td>NCGC00261002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CNc1ccc2oc(C[C@H]3O[C@@]4(CC[C@H]3C)O[C@H]([C@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NCGC00261311-01</td>\n",
       "      <td>NCGC00261311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COc1cc(C(O)CO)ccc1OS(=O)(=O)[O-].[K+]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NCGC00261257-01</td>\n",
       "      <td>NCGC00261257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>COC(=O)N1CCN(C(=O)Cc2ccc(Cl)c(Cl)c2)C(CN2CCCC2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NCGC00260836-01</td>\n",
       "      <td>NCGC00260836</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cc1cc([C@@H]2CCCN2C)on1.Cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NCGC00261756-01</td>\n",
       "      <td>NCGC00261756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Cl-].[Cl-].[Cl-].[Cl-].[Cl-].[Cl-].[NH3+][Ru]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NCGC00261491-01</td>\n",
       "      <td>NCGC00261491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cl.Cl.Oc1ccc2c3c1O[C@H]1c4[nH]c5c(c4C[C@@]4(O)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NCGC00261502-01</td>\n",
       "      <td>NCGC00261502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N[C@@H](CCC(=O)N[C@H](CSN=O)C(=O)NCC(=O)O)C(=O)O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NCGC00261552-01</td>\n",
       "      <td>NCGC00261552</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cl.Cl.c1ccc(C(NCCNC(c2ccccc2)c2ccccc2)c2ccccc2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NCGC00261763-01</td>\n",
       "      <td>NCGC00261763</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Br.C/N=c1/nc(-c2ccccc2)n(-c2ccccc2)s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NCGC00260832-01</td>\n",
       "      <td>NCGC00260832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CN1CCc2cc(NC(=O)Nc3cccnc3)ccc21.Cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NCGC00260772-01</td>\n",
       "      <td>NCGC00260772</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C=CCn1c(=O)c2c(nc(-c3ccc(S(=O)(=O)O)cc3)n2C)n(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NCGC00261543-01</td>\n",
       "      <td>NCGC00261543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COc1cc(C(O)CN)ccc1O.Cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NCGC00261174-01</td>\n",
       "      <td>NCGC00261174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC(=O)CNCCC(c1ccccc1)c1ccccc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NCGC00261524-01</td>\n",
       "      <td>NCGC00261524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>O=[N+]([O-])c1cccc2cn[nH]c12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NCGC00261099-01</td>\n",
       "      <td>NCGC00261099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O=C(O)Cc1ccc(O)c(O)c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NCGC00261743-01</td>\n",
       "      <td>NCGC00261743</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>CCCCCCCC/C=C\\CCCCCCCC(=O)NCCc1ccc(O)c(O)c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NCGC00261301-01</td>\n",
       "      <td>NCGC00261301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Br.CCCN(CCC)C1CCc2ccc(O)cc2C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NCGC00260704-01</td>\n",
       "      <td>NCGC00260704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C[C@H](CCC(=O)NCCS(=O)(=O)O[Na])C1CCC2C3C(C[C@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NCGC00260763-01</td>\n",
       "      <td>NCGC00260763</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Br.Br.N=C(N)SCCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NCGC00261777-01</td>\n",
       "      <td>NCGC00261777</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CC(C)CC(NP(=O)([O-])O[C@@H]1O[C@@H](C)[C@H](O)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NCGC00261010-01</td>\n",
       "      <td>NCGC00261010</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>CNC(=O)[C@H]1O[C@@H](n2cnc3c(NCc4ccc(I)cc4)nc(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>NCGC00261027-01</td>\n",
       "      <td>NCGC00261027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cl.NCC(O)C1CCCCCCC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>NCGC00261946-01</td>\n",
       "      <td>NCGC00261946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N#C/C(=C\\c1ccc(O)c(O)c1)C(=O)c1ccc(O)c(O)c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>NCGC00261303-01</td>\n",
       "      <td>NCGC00261303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C[C@@H](N)Cc1c[nH]cn1.Cl.Cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>NCGC00260825-01</td>\n",
       "      <td>NCGC00260825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Brc1c(Br)c(Br)c2[nH]cnc2c1Br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NCGC00260842-01</td>\n",
       "      <td>NCGC00260842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O=C1NC(=O)/C(=C/c2ccc(-c3ccc(F)cc3O)o2)S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>NCGC00261943-01</td>\n",
       "      <td>NCGC00261943</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CCCn1c(=O)c(C)cn2nc(N)nc12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>NCGC00261228-01</td>\n",
       "      <td>NCGC00261228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CC(C)[C@@H]1CC[C@@H](C)C[C@@H]1P(=O)(c1ccccc1)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>NCGC00261561-01</td>\n",
       "      <td>NCGC00261561</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Br.COc1ccccc1N1CCN(CCCCN2C(=O)c3ccccc3C2=O)CC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>NCGC00261137-01</td>\n",
       "      <td>NCGC00261137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cl.Cl.Clc1ccc(N2CC3CCC(C2)N3)nn1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>NCGC00260748-01</td>\n",
       "      <td>NCGC00260748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Nc1ccc2c3c(cccc13)C(=O)NC2=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>NCGC00261088-01</td>\n",
       "      <td>NCGC00261088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CN(N=O)c1cc(O)ccc1O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NCGC00261249-01</td>\n",
       "      <td>NCGC00261249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N[C@H](C(=O)O)[C@H](O)C(=O)O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>NCGC00261314-01</td>\n",
       "      <td>NCGC00261314</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O=C1C(SCCO)=C(SCCO)C(=O)c2ccccc21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>NCGC00261892-01</td>\n",
       "      <td>NCGC00261892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CCCN(CCC)C1Cc2cc(OC)c(OC)cc2C1.O=C(O)/C=C\\C(=O)O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>NCGC00261537-01</td>\n",
       "      <td>NCGC00261537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C[C@@H]1O[C@H](C[N+](C)(C)C)C[C@H]1O.[Cl-]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>NCGC00261244-01</td>\n",
       "      <td>NCGC00261244</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N=C(N)Nc1ccc2[nH]c3c(c2c1)C[C@@]1(O)[C@H]2Cc4c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>NCGC00260941-01</td>\n",
       "      <td>NCGC00260941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OC[C@H]1O[C@H](n2cnc3c(N[C@H]4CCC[C@@H]4O)ncnc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>NCGC00261846-01</td>\n",
       "      <td>NCGC00261846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Cc1ccc(O)c(N=Nc2ccccc2)n1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>NCGC00261078-01</td>\n",
       "      <td>NCGC00261078</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cn1c(=O)c2c(nc(/C=C/c3cccc(Cl)c3)n2C)n(C)c1=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NCGC00261276-01</td>\n",
       "      <td>NCGC00261276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Br.NCc1cc(O)no1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>NCGC00261425-01</td>\n",
       "      <td>NCGC00261425</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>O=c1c(O)c(-c2cc(O)c(O)c(O)c2)oc2cc(O)cc(O)c12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>NCGC00261931-01</td>\n",
       "      <td>NCGC00261931</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C[C@H](N)Cc1cccc(C(F)(F)F)c1.Cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>NCGC00261836-01</td>\n",
       "      <td>NCGC00261836</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cl.O=C(O)C1CCCN(CCC=C(c2ccccc2)c2ccccc2)C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>NCGC00260749-01</td>\n",
       "      <td>NCGC00260749</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC(CCP(=O)(O)O)C(=O)O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>NCGC00260887-01</td>\n",
       "      <td>NCGC00260887</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CC(/C=C/c1cccc(Oc2ccc(F)cc2)c1)N(O)C(N)=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>NCGC00261194-01</td>\n",
       "      <td>NCGC00261194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CN(C)c1cc2c(Nc3ccc4c(cnn4Cc4ccccc4)c3)ncnc2cn1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>NCGC00261074-01</td>\n",
       "      <td>NCGC00261074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cn1c(=O)[nH]c2ncn(C)c2c1=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>NCGC00261462-01</td>\n",
       "      <td>NCGC00261462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CC(=O)O.CSC(=N)NCCC[C@H](N)C(=O)O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>NCGC00260745-01</td>\n",
       "      <td>NCGC00260745</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N=C(N)NCCCCN.O=S(=O)(O)O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>NCGC00260729-01</td>\n",
       "      <td>NCGC00260729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CC(=O)NCCc1c[nH]c2ccc(O)cc12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Compound Batch ID   Compound ID NR-AR NR-AR-LBD NR-AhR NR-Aromatase NR-ER  \\\n",
       "0     NCGC00261443-01  NCGC00261443     0         0      0          NaN     0   \n",
       "1     NCGC00261600-01  NCGC00261600     0         0    NaN          NaN     1   \n",
       "2     NCGC00260926-01  NCGC00260926     0       NaN      1          NaN     0   \n",
       "3     NCGC00261266-01  NCGC00261266     0         0      0            0     0   \n",
       "4     NCGC00261897-01  NCGC00261897     1         0      0            0   NaN   \n",
       "5     NCGC00261559-01  NCGC00261559     0         0      0            0     0   \n",
       "6     NCGC00261121-01  NCGC00261121     0         0      0          NaN     0   \n",
       "7     NCGC00261374-01  NCGC00261374     0         0      0            0     0   \n",
       "8     NCGC00261612-01  NCGC00261612     0         0      0            0     0   \n",
       "9     NCGC00261002-01  NCGC00261002     0         0    NaN          NaN   NaN   \n",
       "10    NCGC00261311-01  NCGC00261311     0         0      0            0     0   \n",
       "11    NCGC00261257-01  NCGC00261257     0         0      0            0     0   \n",
       "12    NCGC00260836-01  NCGC00260836     0         0      0            0     0   \n",
       "13    NCGC00261756-01  NCGC00261756     0         0      0            0     0   \n",
       "14    NCGC00261491-01  NCGC00261491     0         0      0            0     0   \n",
       "15    NCGC00261502-01  NCGC00261502     0         0      0            0     0   \n",
       "16    NCGC00261552-01  NCGC00261552     0       NaN      0          NaN   NaN   \n",
       "17    NCGC00261763-01  NCGC00261763     0         0      0          NaN     0   \n",
       "18    NCGC00260832-01  NCGC00260832   NaN         0      1          NaN     1   \n",
       "19    NCGC00260772-01  NCGC00260772     0         0      0            0     0   \n",
       "20    NCGC00261543-01  NCGC00261543     0         0      0            0     0   \n",
       "21    NCGC00261174-01  NCGC00261174     0         0      0            0     0   \n",
       "22    NCGC00261524-01  NCGC00261524     0         0      0            0     0   \n",
       "23    NCGC00261099-01  NCGC00261099     0         0      0            0     0   \n",
       "24    NCGC00261743-01  NCGC00261743     0         0      0          NaN     0   \n",
       "25    NCGC00261301-01  NCGC00261301     0         0      0            0   NaN   \n",
       "26    NCGC00260704-01  NCGC00260704     0         0      0            0     0   \n",
       "27    NCGC00260763-01  NCGC00260763     0       NaN      0            0     0   \n",
       "28    NCGC00261777-01  NCGC00261777     0         0      0            0     0   \n",
       "29    NCGC00261010-01  NCGC00261010     0       NaN      0            0     0   \n",
       "..                ...           ...   ...       ...    ...          ...   ...   \n",
       "120   NCGC00261027-01  NCGC00261027     0         0      0            0     0   \n",
       "121   NCGC00261946-01  NCGC00261946     0         0      0            0     0   \n",
       "122   NCGC00261303-01  NCGC00261303     0         0      0            0     0   \n",
       "123   NCGC00260825-01  NCGC00260825     0         0      0            1     1   \n",
       "124   NCGC00260842-01  NCGC00260842   NaN       NaN      0          NaN     1   \n",
       "125   NCGC00261943-01  NCGC00261943     0         0      0            0     0   \n",
       "126   NCGC00261228-01  NCGC00261228     0         0      0            0   NaN   \n",
       "127   NCGC00261561-01  NCGC00261561     0         0      0            0     0   \n",
       "128   NCGC00261137-01  NCGC00261137     0         0      0            0     0   \n",
       "129   NCGC00260748-01  NCGC00260748     0         0      0          NaN     0   \n",
       "130   NCGC00261088-01  NCGC00261088     0         0      1          NaN     0   \n",
       "131   NCGC00261249-01  NCGC00261249     0         0      0            0     1   \n",
       "132   NCGC00261314-01  NCGC00261314     0       NaN    NaN            1   NaN   \n",
       "133   NCGC00261892-01  NCGC00261892     0         0      0            0     0   \n",
       "134   NCGC00261537-01  NCGC00261537     0         0      0            0     0   \n",
       "135   NCGC00261244-01  NCGC00261244     0         0    NaN            0     0   \n",
       "136   NCGC00260941-01  NCGC00260941     0         0      0            0     0   \n",
       "137   NCGC00261846-01  NCGC00261846     0         0      1          NaN     0   \n",
       "138   NCGC00261078-01  NCGC00261078     0         0    NaN            0     0   \n",
       "139   NCGC00261276-01  NCGC00261276     0         0      0            0     0   \n",
       "140   NCGC00261425-01  NCGC00261425     0         0      0            0     0   \n",
       "141   NCGC00261931-01  NCGC00261931     0         0      0            0     0   \n",
       "142   NCGC00261836-01  NCGC00261836     0         0      0            0     0   \n",
       "143   NCGC00260749-01  NCGC00260749     0         0      0            0     0   \n",
       "144   NCGC00260887-01  NCGC00260887     0         0    NaN          NaN     0   \n",
       "145   NCGC00261194-01  NCGC00261194     0         0      1          NaN     0   \n",
       "146   NCGC00261074-01  NCGC00261074     0         0      0            0     0   \n",
       "147   NCGC00261462-01  NCGC00261462     0         0      0            0     0   \n",
       "148   NCGC00260745-01  NCGC00260745     0         0      0            0     0   \n",
       "149   NCGC00260729-01  NCGC00260729     0         0      0            0     0   \n",
       "\n",
       "    NR-ER-LBD NR-PPAR-gamma SR-ARE SR-ATAD5 SR-HSE SR-MMP SR-p53  \\\n",
       "0           0             0      0        1      0      0      0   \n",
       "1         NaN             0    NaN        1    NaN    NaN      1   \n",
       "2         NaN           NaN      1      NaN      1    NaN      0   \n",
       "3           0             0      0        0      0      0      0   \n",
       "4           0             0      1        1      0    NaN      0   \n",
       "5           0             0      0        0      0      0      0   \n",
       "6           0             0      0        0      0      0      0   \n",
       "7           0             0      0        0      0      0      0   \n",
       "8           0             0      0        0      0      0      0   \n",
       "9           0           NaN      1        0      1      1      1   \n",
       "10          0             0      0        0      0      0      0   \n",
       "11          0             0      0        0      0    NaN      0   \n",
       "12          0             0      0        0      0      0      0   \n",
       "13          0             0      0        0      0      0      0   \n",
       "14          0             0      0        0      0      0      0   \n",
       "15          0             0      0        0      0      0      0   \n",
       "16          0             0    NaN        0      0    NaN    NaN   \n",
       "17          0             0      1        1      0      0      0   \n",
       "18          0             0      0        0      0    NaN      0   \n",
       "19          0             0      0        0      0      0      0   \n",
       "20          0             0      0        0      0      0      0   \n",
       "21          0             0      0        0      0      0      0   \n",
       "22          0             0      0        0      0    NaN      0   \n",
       "23          0             0      0        0      0      0      0   \n",
       "24          0             0      0      NaN    NaN      1      0   \n",
       "25          0             0      0        0      0      0      0   \n",
       "26          0             0      0        0      0      0      0   \n",
       "27          0             0      0        0      0      0      0   \n",
       "28          0             0      0        0      0      0      0   \n",
       "29          0           NaN      0        0      0    NaN      1   \n",
       "..        ...           ...    ...      ...    ...    ...    ...   \n",
       "120         0             0      0        0      0      0      0   \n",
       "121         0             0    NaN        0      0      1      0   \n",
       "122         0             0    NaN        0      0      0      0   \n",
       "123         0           NaN    NaN      NaN      0    NaN      0   \n",
       "124         1           NaN    NaN      NaN      0      1    NaN   \n",
       "125         0             0      0        0      0      0      0   \n",
       "126         0             0      0        0      0      0      0   \n",
       "127         0             0      0        0      0      0      0   \n",
       "128         0             0      0        0      0      0      0   \n",
       "129         0             0      0        0      0    NaN      0   \n",
       "130         0             0      1        0      0      0      0   \n",
       "131         0             0      0        0      0      0      0   \n",
       "132         0           NaN      1      NaN      1      1    NaN   \n",
       "133         0             0      0        0      0      0      0   \n",
       "134         0             0      0        0      0      0      0   \n",
       "135         0             0      0        1    NaN      0      0   \n",
       "136         0             1      0        1      0      0      0   \n",
       "137         0           NaN      1        1      0      1      0   \n",
       "138         0             0    NaN        0      0      0    NaN   \n",
       "139         0             0      0        0      0      0      0   \n",
       "140         0             0    NaN        0      0      1      0   \n",
       "141         0             0      0        0      0      0      0   \n",
       "142         0             0      0        0      0      0      0   \n",
       "143         0             0      0        0      0      0      0   \n",
       "144         0             0    NaN        0      0      0      1   \n",
       "145         0             0      1        0      0    NaN    NaN   \n",
       "146         0             0      0        0      0      0      0   \n",
       "147         0             0      0        0      0      0      0   \n",
       "148         0             0      0        0      0      0      0   \n",
       "149         0             0    NaN        0      0      0      0   \n",
       "\n",
       "                                                smiles  \n",
       "0          CNc1ncnc2c1ncn2[C@@H]1O[C@H](CO)C(O)[C@H]1O  \n",
       "1                    Oc1cc(O)cc(/C=C/c2ccc(O)c(O)c2)c1  \n",
       "2    COc1ccc2c(c[n+](C)c3c4cc5c(cc4ccc23)OCO5)c1OC....  \n",
       "3                            Br.Cc1onc(O)c1CC(N)C(=O)O  \n",
       "4                        Nc1nc(N)c(N=O)c(OCC2CCCCC2)n1  \n",
       "5            c1ccc2c(c1)CC(N1CCN(c3cccc4c3OCCO4)CC1)C2  \n",
       "6                     Cl.Oc1cc2c(cc1O)C(c1ccccc1)CNCC2  \n",
       "7                       Cl.N=C(N)c1ccc(CS(=O)(=O)F)cc1  \n",
       "8                Cl.O=C(OCCN1CCOCC1)C1(c2ccccc2)CCCCC1  \n",
       "9    CNc1ccc2oc(C[C@H]3O[C@@]4(CC[C@H]3C)O[C@H]([C@...  \n",
       "10               COc1cc(C(O)CO)ccc1OS(=O)(=O)[O-].[K+]  \n",
       "11   COC(=O)N1CCN(C(=O)Cc2ccc(Cl)c(Cl)c2)C(CN2CCCC2...  \n",
       "12                          Cc1cc([C@@H]2CCCN2C)on1.Cl  \n",
       "13   [Cl-].[Cl-].[Cl-].[Cl-].[Cl-].[Cl-].[NH3+][Ru]...  \n",
       "14   Cl.Cl.Oc1ccc2c3c1O[C@H]1c4[nH]c5c(c4C[C@@]4(O)...  \n",
       "15    N[C@@H](CCC(=O)N[C@H](CSN=O)C(=O)NCC(=O)O)C(=O)O  \n",
       "16   Cl.Cl.c1ccc(C(NCCNC(c2ccccc2)c2ccccc2)c2ccccc2...  \n",
       "17               Br.C/N=c1/nc(-c2ccccc2)n(-c2ccccc2)s1  \n",
       "18                  CN1CCc2cc(NC(=O)Nc3cccnc3)ccc21.Cl  \n",
       "19   C=CCn1c(=O)c2c(nc(-c3ccc(S(=O)(=O)O)cc3)n2C)n(...  \n",
       "20                              COc1cc(C(O)CN)ccc1O.Cl  \n",
       "21                       NC(=O)CNCCC(c1ccccc1)c1ccccc1  \n",
       "22                        O=[N+]([O-])c1cccc2cn[nH]c12  \n",
       "23                               O=C(O)Cc1ccc(O)c(O)c1  \n",
       "24          CCCCCCCC/C=C\\CCCCCCCC(=O)NCCc1ccc(O)c(O)c1  \n",
       "25                       Br.CCCN(CCC)C1CCc2ccc(O)cc2C1  \n",
       "26   C[C@H](CCC(=O)NCCS(=O)(=O)O[Na])C1CCC2C3C(C[C@...  \n",
       "27                                    Br.Br.N=C(N)SCCN  \n",
       "28   CC(C)CC(NP(=O)([O-])O[C@@H]1O[C@@H](C)[C@H](O)...  \n",
       "29   CNC(=O)[C@H]1O[C@@H](n2cnc3c(NCc4ccc(I)cc4)nc(...  \n",
       "..                                                 ...  \n",
       "120                                Cl.NCC(O)C1CCCCCCC1  \n",
       "121        N#C/C(=C\\c1ccc(O)c(O)c1)C(=O)c1ccc(O)c(O)c1  \n",
       "122                        C[C@@H](N)Cc1c[nH]cn1.Cl.Cl  \n",
       "123                       Brc1c(Br)c(Br)c2[nH]cnc2c1Br  \n",
       "124          O=C1NC(=O)/C(=C/c2ccc(-c3ccc(F)cc3O)o2)S1  \n",
       "125                         CCCn1c(=O)c(C)cn2nc(N)nc12  \n",
       "126  CC(C)[C@@H]1CC[C@@H](C)C[C@@H]1P(=O)(c1ccccc1)...  \n",
       "127     Br.COc1ccccc1N1CCN(CCCCN2C(=O)c3ccccc3C2=O)CC1  \n",
       "128                   Cl.Cl.Clc1ccc(N2CC3CCC(C2)N3)nn1  \n",
       "129                       Nc1ccc2c3c(cccc13)C(=O)NC2=O  \n",
       "130                                CN(N=O)c1cc(O)ccc1O  \n",
       "131                       N[C@H](C(=O)O)[C@H](O)C(=O)O  \n",
       "132                  O=C1C(SCCO)=C(SCCO)C(=O)c2ccccc21  \n",
       "133   CCCN(CCC)C1Cc2cc(OC)c(OC)cc2C1.O=C(O)/C=C\\C(=O)O  \n",
       "134         C[C@@H]1O[C@H](C[N+](C)(C)C)C[C@H]1O.[Cl-]  \n",
       "135  N=C(N)Nc1ccc2[nH]c3c(c2c1)C[C@@]1(O)[C@H]2Cc4c...  \n",
       "136  OC[C@H]1O[C@H](n2cnc3c(N[C@H]4CCC[C@@H]4O)ncnc...  \n",
       "137                          Cc1ccc(O)c(N=Nc2ccccc2)n1  \n",
       "138      Cn1c(=O)c2c(nc(/C=C/c3cccc(Cl)c3)n2C)n(C)c1=O  \n",
       "139                                    Br.NCc1cc(O)no1  \n",
       "140      O=c1c(O)c(-c2cc(O)c(O)c(O)c2)oc2cc(O)cc(O)c12  \n",
       "141                    C[C@H](N)Cc1cccc(C(F)(F)F)c1.Cl  \n",
       "142         Cl.O=C(O)C1CCCN(CCC=C(c2ccccc2)c2ccccc2)C1  \n",
       "143                              NC(CCP(=O)(O)O)C(=O)O  \n",
       "144          CC(/C=C/c1cccc(Oc2ccc(F)cc2)c1)N(O)C(N)=O  \n",
       "145     CN(C)c1cc2c(Nc3ccc4c(cnn4Cc4ccccc4)c3)ncnc2cn1  \n",
       "146                         Cn1c(=O)[nH]c2ncn(C)c2c1=O  \n",
       "147                  CC(=O)O.CSC(=N)NCCC[C@H](N)C(=O)O  \n",
       "148                           N=C(N)NCCCCN.O=S(=O)(O)O  \n",
       "149                       CC(=O)NCCc1c[nH]c2ccc(O)cc12  \n",
       "\n",
       "[150 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label']='active'\n",
    "data.head(5)\n",
    "data.to_csv(basename + '_pandas.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lines processed.\n",
      "1000 lines processed.\n",
      "2000 lines processed.\n",
      "3000 lines processed.\n",
      "4000 lines processed.\n",
      "5000 lines processed.\n",
      "6000 lines processed.\n",
      "7000 lines processed.\n",
      "8000 lines processed.\n",
      "9000 lines processed.\n",
      "10000 lines processed.\n",
      "10460 SMILES retrieved\n",
      "Number of characters: 47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'\\n',\n",
       " '#',\n",
       " '(',\n",
       " ')',\n",
       " '-',\n",
       " '/',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '=',\n",
       " 'C',\n",
       " 'F',\n",
       " 'I',\n",
       " 'L',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'R',\n",
       " 'S',\n",
       " '[C-]',\n",
       " '[C@@H]',\n",
       " '[C@@]',\n",
       " '[C@H]',\n",
       " '[CH-]',\n",
       " '[N+]',\n",
       " '[N-]',\n",
       " '[NH+]',\n",
       " '[NH-]',\n",
       " '[NH2+]',\n",
       " '[NH3+]',\n",
       " '[O-]',\n",
       " '[OH+]',\n",
       " '[S-]',\n",
       " '[SH+]',\n",
       " '[n+]',\n",
       " '[n-]',\n",
       " '[nH+]',\n",
       " '[nH]',\n",
       " '\\\\',\n",
       " 'c',\n",
       " 'n',\n",
       " 'o',\n",
       " 's'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "def canonicalize_smiles_from_file(fname):\n",
    "    \"\"\"Reads a SMILES file and returns a list of RDKIT SMILES\"\"\"\n",
    "    with open(fname, 'r') as f:\n",
    "        smiles_list = []\n",
    "        for i, line in enumerate(f):\n",
    "            if i % 1000 == 0:\n",
    "                print(\"{} lines processed.\".format(i))\n",
    "            smiles = line.split(\" \")[0]\n",
    "            mol = Chem.MolFromSmiles(smiles)          \n",
    "            smiles_list.append(smiles)\n",
    "        print(\"{} SMILES retrieved\".format(len(smiles_list)))\n",
    "        return smiles_list\n",
    "\n",
    "def construct_vocabulary(smiles_list,fname):\n",
    "    \"\"\"Returns all the characters present in a SMILES file.\n",
    "       Uses regex to find characters/tokens of the format '[x]'.\"\"\"\n",
    "    add_chars = set()\n",
    "    for i, smiles in enumerate(smiles_list):\n",
    "        regex = '(\\[[^\\[\\]]{1,10}\\])'\n",
    "        smiles = data_structs.replace_halogen(smiles)\n",
    "        char_list = re.split(regex, smiles)\n",
    "        for char in char_list:\n",
    "            if char.startswith('['):\n",
    "                add_chars.add(char)\n",
    "\n",
    "            else:\n",
    "                chars = [unit for unit in char]\n",
    "                [add_chars.add(unit) for unit in chars]\n",
    "\n",
    "    print(\"Number of characters: {}\".format(len(add_chars)))\n",
    "    with open(fname, 'w') as f:\n",
    "        for char in add_chars:\n",
    "            f.write(char + \"\\n\")\n",
    "    return add_chars\n",
    "\n",
    "smiles_list = canonicalize_smiles_from_file('data/fnta_all_pandas.smi')\n",
    "construct_vocabulary(smiles_list,'data/Voc-pharma')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', 'R', '[NH2+]', '[NH-]', '[NH3+]', '[N+]', '3', 'I', 'N', '[NH+]', '[C-]', 'o', '[n-]', '[C@@]', '[nH]', 'n', ')', '[C@H]', '[C@@H]', 'C', '#', '=', '[O-]', 'c', '[n+]', '(', '1', 'S', '5', '[nH+]', '[CH-]', '7', 'L', 'F', '[SH+]', '[OH+]', 's', '2', '[N-]', 'P', '[S-]', '/', '\\\\', '6', '-', '4', 'O']\n",
      "7485\n",
      "1872\n",
      "2 properties\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import data_structs\n",
    "import re\n",
    "import string\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "torch.manual_seed(1018) #ä¸ºCPUè®¾ç½®ç§å­ç”¨äºŽç”Ÿæˆéšæœºæ•°ï¼Œä»¥ä½¿å¾—ç»“æžœæ˜¯ç¡®å®šçš„\n",
    "\n",
    "torch.cuda.manual_seed(1018)\n",
    "    \n",
    "#data processing\n",
    "class ProDataset(Dataset):\n",
    "    \"\"\" Diabetes dataset.\"\"\"\n",
    "\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self, is_train_set=False):\n",
    "        filename = './data/fnta-train.csv' if is_train_set else './data/fnta-test.csv'\n",
    "        with open(filename, \"rt\") as f:\n",
    "            reader = csv.reader(f)\n",
    "            rows = list(reader)\n",
    "        \n",
    "        self.lines = [row[0] for row in rows]\n",
    "        self.properties = [row[1] for row in rows]\n",
    "        self.len = len(self.properties)\n",
    "\n",
    "        self.property_list = ['inactive', 'active']\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.lines[index], self.properties[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def get_properties(self):\n",
    "        return self.property_list\n",
    "\n",
    "    def get_property(self, id):\n",
    "\n",
    "        return self.property_list[id]\n",
    "\n",
    "    def get_property_id(self, property):\n",
    "        return self.property_list.index(property)\n",
    "\n",
    "\n",
    "\n",
    "# Voc loaders\n",
    "with open('data/Voc-pharma', 'r') as f:\n",
    "    chars = f.read().split()\n",
    "print(chars)\n",
    "all_letters = chars\n",
    "Batch_size = 64\n",
    "N_CHARS = len(all_letters)\n",
    "\n",
    "test_dataset = ProDataset(is_train_set=False)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=Batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "\n",
    "train_dataset = ProDataset(is_train_set=True)\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=Batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "print(len(train_loader.dataset))\n",
    "print(len(test_loader.dataset))\n",
    "\n",
    "N_PROPERTIES = len(train_dataset.get_properties())\n",
    "print(N_PROPERTIES, \"properties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inactive', 'active']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.get_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = dict(zip(all_letters, range(len(all_letters))))\n",
    "id_to_word = {v: k for k, v in word_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 46,  21,  19,  25,  19,  23,  26,  23,  23,  15,  23,  23,\n",
       "           26,  16,   8,  26,  19,  19,   8,  25,  19,  37,  23,   6,\n",
       "           23,  23,  23,  25,  32,  16,  23,  23,   6,  27,  19,  23,\n",
       "            6,  23,  23,  23,  15,  23,   6,  37,  16,  19,  19,  26]], device='cuda:0'),\n",
       " tensor([ 48], device='cuda:0'),\n",
       " tensor([ 1], device='cuda:0'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some utility functions\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def create_variable(tensor):\n",
    "    # Do cuda() before wrapping with variable\n",
    "    if torch.cuda.is_available():\n",
    "        return Variable(tensor.cuda())\n",
    "    else:\n",
    "        return Variable(tensor)\n",
    "\n",
    "# pad sequences and sort the tensor\n",
    "def pad_sequences(vectorized_seqs, seq_lengths, properties):\n",
    "    seq_tensor = torch.zeros((len(vectorized_seqs), seq_lengths.max())).long()\n",
    "    for idx, (seq, seq_len) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
    "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
    "\n",
    "    # Sort tensors by their length\n",
    "    seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
    "    seq_tensor = seq_tensor[perm_idx]\n",
    "\n",
    "    # Also sort the target (countries) in the same order\n",
    "    target = properties2tensor(properties)\n",
    "    if len(properties):\n",
    "        target = target[perm_idx]\n",
    "\n",
    "    # Return variables\n",
    "    # DataParallel requires everything to be a Variable\n",
    "    return create_variable(seq_tensor), \\\n",
    "        create_variable(seq_lengths), \\\n",
    "        create_variable(target)\n",
    "\n",
    "# Create necessary variables, lengths, and target\n",
    "def make_variables(lines, properties):\n",
    "    sequence_and_length = [line2voc_arr(line) for line in lines]\n",
    "    vectorized_seqs = [sl[0] for sl in sequence_and_length]\n",
    "    seq_lengths = torch.LongTensor([sl[1] for sl in sequence_and_length])\n",
    "    return pad_sequences(vectorized_seqs, seq_lengths, properties)\n",
    "\n",
    "#used to put char into acsii index,ord() will return the index of ascii ie. ord(c) =99\n",
    "def str2ascii_arr(msg):\n",
    "    arr = [ord(c) for c in msg]\n",
    "    return arr, len(arr)\n",
    "\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.index(letter)\n",
    "# print(letterToIndex('c'))\n",
    "\n",
    "def line2voc_arr(line):\n",
    "    arr = []\n",
    "    regex = '(\\[[^\\[\\]]{1,10}\\])'\n",
    "    line = data_structs.replace_halogen(line)\n",
    "    char_list = re.split(regex, line)\n",
    "    for li, char in enumerate(char_list):\n",
    "        if char.startswith('['):\n",
    "               arr.append(letterToIndex(char)) \n",
    "        else:\n",
    "            chars = [unit for unit in char]\n",
    "\n",
    "            for i, unit in enumerate(chars):\n",
    "                arr.append(letterToIndex(unit))\n",
    "    return arr, len(arr)\n",
    "\n",
    "\n",
    "\n",
    "def properties2tensor(properties):\n",
    "    property_ids = [train_dataset.get_property_id(\n",
    "        property) for property in properties]\n",
    "    return torch.LongTensor(property_ids)\n",
    "\n",
    "make_variables([\"O=C(Cc1ccncc1)N1CCN(C2c3ccc(Cl)cc3SCc3cccnc32)CC1\"],['active'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "def binary_classfication(attention_model,train_loader,epochs=5,use_regularization=True,C=1.0,clip=True):\n",
    "#     attention_model.cuda()\n",
    "    loss = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(attention_model.parameters())\n",
    "    train(attention_model,train_loader,loss,optimizer,epochs,use_regularization,C,clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,keras\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    " \n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import data_structs\n",
    "import re\n",
    "import string\n",
    "#from matenature_dataset import ProDataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class StructuredSelfAttention(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The class is an implementation of the paper A Structured Self-Attentive Sentence Embedding including regularization\n",
    "    and without pruning. Slight modifications have been done for speedup\n",
    "    \"\"\"\n",
    "   \n",
    "    def __init__(self,batch_size,lstm_hid_dim,d_a,r,max_len,emb_dim=100,vocab_size=None,use_pretrained_embeddings = False,embeddings=None,type=0,n_classes = 1):\n",
    "        \"\"\"\n",
    "        Initializes parameters suggested in paper\n",
    " \n",
    "        Args:\n",
    "            batch_size  : {int} batch_size used for training\n",
    "            lstm_hid_dim: {int} hidden dimension for lstm\n",
    "            d_a         : {int} hidden dimension for the dense layer\n",
    "            r           : {int} attention-hops or attention heads\n",
    "            max_len     : {int} number of lstm timesteps\n",
    "            emb_dim     : {int} embeddings dimension\n",
    "            vocab_size  : {int} size of the vocabulary\n",
    "            use_pretrained_embeddings: {bool} use or train your own embeddings\n",
    "            embeddings  : {torch.FloatTensor} loaded pretrained embeddings\n",
    "            type        : [0,1] 0-->binary_classification 1-->multiclass classification\n",
    "            n_classes   : {int} number of classes\n",
    " \n",
    "        Returns:\n",
    "            self\n",
    " \n",
    "        Raises:\n",
    "            Exception\n",
    "        \"\"\"\n",
    "        super(StructuredSelfAttention,self).__init__()\n",
    "       \n",
    "        self.embeddings = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = torch.nn.LSTM(emb_dim,lstm_hid_dim,1,batch_first=True)\n",
    "        self.linear_first = torch.nn.Linear(lstm_hid_dim,d_a)\n",
    "        self.linear_first.bias.data.fill_(0)\n",
    "        self.linear_second = torch.nn.Linear(d_a,r)\n",
    "        self.linear_second.bias.data.fill_(0)\n",
    "        self.n_classes = n_classes\n",
    "        self.linear_final = torch.nn.Linear(lstm_hid_dim,self.n_classes)\n",
    "        self.batch_size = batch_size       \n",
    "        self.max_len = max_len\n",
    "        self.lstm_hid_dim = lstm_hid_dim\n",
    "        self.hidden_state = self.init_hidden()\n",
    "        self.r = r\n",
    "        self.type = type\n",
    "                 \n",
    "    def _load_embeddings(self,use_pretrained_embeddings,embeddings,vocab_size,emb_dim):\n",
    "        \"\"\"Load the embeddings based on flag\"\"\"\n",
    "       \n",
    "#         if use_pretrained_embeddings is True and embeddings is None:\n",
    "#             raise Exception(\"Send a pretrained word embedding as an argument\")\n",
    "           \n",
    "#         if not use_pretrained_embeddings and vocab_size is None:\n",
    "#             raise Exception(\"Vocab size cannot be empty\")\n",
    "   \n",
    "        if not use_pretrained_embeddings:\n",
    "            word_embeddings = torch.nn.Embedding(vocab_size,emb_dim,padding_idx=0)\n",
    "            \n",
    "#         elif use_pretrained_embeddings:\n",
    "#             word_embeddings = torch.nn.Embedding(embeddings.size(0), embeddings.size(1))\n",
    "#             word_embeddings.weight = torch.nn.Parameter(embeddings)\n",
    "#             emb_dim = embeddings.size(1)\n",
    "            \n",
    "        return word_embeddings,emb_dim\n",
    "       \n",
    "        \n",
    "    def softmax(self,input, axis=1):\n",
    "        \"\"\"\n",
    "        Softmax applied to axis=n\n",
    " \n",
    "        Args:\n",
    "           input: {Tensor,Variable} input on which softmax is to be applied\n",
    "           axis : {int} axis on which softmax is to be applied\n",
    " \n",
    "        Returns:\n",
    "            softmaxed tensors\n",
    " \n",
    "       \n",
    "        \"\"\"\n",
    " \n",
    "        input_size = input.size()\n",
    "        trans_input = input.transpose(axis, len(input_size)-1)\n",
    "        trans_size = trans_input.size()\n",
    "        input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
    "        soft_max_2d = F.softmax(input_2d)\n",
    "        soft_max_nd = soft_max_2d.view(*trans_size)\n",
    "        return soft_max_nd.transpose(axis, len(input_size)-1)\n",
    "       \n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (Variable(torch.zeros(1,self.batch_size,self.lstm_hid_dim).cuda()),Variable(torch.zeros(1,self.batch_size,self.lstm_hid_dim)).cuda())\n",
    "       \n",
    "        \n",
    "    def forward(self,x,seq_len):\n",
    "#         x = x.t()\n",
    "        embeddings = self.embeddings(x) \n",
    "#         print(embeddings.size())\n",
    "        outputs, self.hidden_state = self.lstm(embeddings,self.hidden_state)    #åº”è¯¥æ˜¯ batch * seqlenth * embed\n",
    "        x = F.tanh(self.linear_first(outputs))       \n",
    "        x = self.linear_second(x)       \n",
    "        x = self.softmax(x,1)       \n",
    "        attention = x.transpose(1,2)       \n",
    "        sentence_embeddings = attention@outputs       \n",
    "        avg_sentence_embeddings = torch.sum(sentence_embeddings,1)/self.r\n",
    "       \n",
    "        if not bool(self.type):\n",
    "            output = F.sigmoid(self.linear_final(avg_sentence_embeddings))\n",
    "           \n",
    "            return output,attention\n",
    "        else:\n",
    "            return F.log_softmax(self.linear_final(avg_sentence_embeddings)),attention\n",
    "       \n",
    "\t   \n",
    "\t#Regularization\n",
    "    def l2_matrix_norm(self,m):\n",
    "        \"\"\"\n",
    "        Frobenius norm calculation\n",
    " \n",
    "        Args:\n",
    "           m: {Variable} ||AAT - I||\n",
    " \n",
    "        Returns:\n",
    "            regularized value\n",
    " \n",
    "       \n",
    "        \"\"\"\n",
    "        return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredSelfAttention(\n",
       "  (embeddings): Embedding(47, 100)\n",
       "  (lstm): LSTM(100, 256, batch_first=True)\n",
       "  (linear_first): Linear(in_features=256, out_features=100, bias=True)\n",
       "  (linear_second): Linear(in_features=100, out_features=20, bias=True)\n",
       "  (linear_final): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = None\n",
    " \n",
    "attention_model = StructuredSelfAttention(batch_size=Batch_size,lstm_hid_dim=256,d_a = 100,r=20,vocab_size=len(word_to_id),type=0,n_classes=1,max_len=200,use_pretrained_embeddings=False,embeddings=None)\n",
    "attention_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    " \n",
    "def train(attention_model,train_loader,criterion,optimizer,epochs = 5,use_regularization = False,C=0,clip=False):\n",
    "    \"\"\"\n",
    "        Training code\n",
    " \n",
    "        Args:\n",
    "            attention_model : {object} model\n",
    "            train_loader    : {DataLoader} training data loaded into a dataloader\n",
    "            optimizer       :  optimizer\n",
    "            criterion       :  loss function. Must be BCELoss for binary_classification and NLLLoss for multiclass\n",
    "            epochs          : {int} number of epochs\n",
    "            use_regularizer : {bool} use penalization or not\n",
    "            C               : {int} penalization coeff\n",
    "            clip            : {bool} use gradient clipping or not\n",
    "       \n",
    "        Returns:\n",
    "            accuracy and losses of the model\n",
    " \n",
    "      \n",
    "        \"\"\"\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "    for i in range(epochs):\n",
    "        print(\"Running EPOCH\",i+1)\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        correct = 0\n",
    "       \n",
    "        for batch_idx,(lines, properties) in enumerate(train_loader):  \n",
    "            \n",
    "            input, seq_lengths, y = make_variables(lines, properties)\n",
    "            \n",
    "#              y = torch.DoubleTensor(y)\n",
    "            \n",
    "            attention_model.hidden_state = attention_model.init_hidden()\n",
    "\n",
    "            y_pred,att = attention_model(input,seq_lengths)\n",
    "           \n",
    "            #penalization AAT - I\n",
    "            if use_regularization:\n",
    "                attT = att.transpose(1,2)\n",
    "                identity = torch.eye(att.size(1))\n",
    "                identity = Variable(identity.unsqueeze(0).expand(train_loader.batch_size,att.size(1),att.size(1))).cuda()\n",
    "                penal = attention_model.l2_matrix_norm(att@attT - identity)\n",
    "           \n",
    "            \n",
    "            if not bool(attention_model.type) :\n",
    "                #binary classification\n",
    "                #Adding a very small value to prevent BCELoss from outputting NaN's\n",
    "                correct+=torch.eq(torch.round(y_pred.type(torch.DoubleTensor).squeeze(1)),y.type(torch.DoubleTensor)).data.sum()\n",
    "#                 print(correct.numpy()/(len(train_loader.dataset)))\n",
    "#                 if use_regularization:\n",
    "#                     try:\n",
    "#                         loss = criterion(y_pred.type(torch.DoubleTensor).squeeze(1)+1e-8,y) + C * penal/train_loader.batch_size\n",
    "                       \n",
    "#                     except RuntimeError:\n",
    "#                         raise Exception(\"BCELoss gets nan values on regularization. Either remove regularization or add very small values\")\n",
    "#                 else:\n",
    "                loss = criterion(y_pred.type(torch.DoubleTensor).squeeze(1),y.type(torch.DoubleTensor))\n",
    "                \n",
    "            \n",
    "            # else:\n",
    "                \n",
    "            #     correct+=torch.eq(torch.max(y_pred,1)[1],y.type(torch.LongTensor)).data.sum()\n",
    "            #     if use_regularization:\n",
    "            #         loss = criterion(y_pred,y) + (C * penal/train_loader.batch_size).type(torch.FloatTensor)\n",
    "            #     else:\n",
    "            #         loss = criterion(y_pred,y)\n",
    "               \n",
    " \n",
    "            total_loss+=loss.data\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "           \n",
    "            #gradient clipping\n",
    "            if clip:\n",
    "                torch.nn.utils.clip_grad_norm(attention_model.parameters(),0.5)\n",
    "            optimizer.step()\n",
    "            n_batches+=1\n",
    "           \n",
    "        print(\"avg_loss is\",total_loss/n_batches)\n",
    "        print(\"Accuracy of the model\",correct.numpy()/(len(train_loader.dataset)))\n",
    "        \n",
    "        test(attention_model,test_loader,loss)\n",
    "        \n",
    "        losses.append(total_loss/n_batches)\n",
    "        accuracy.append(correct/(n_batches*train_loader.batch_size))\n",
    "    return losses,accuracy\n",
    " \n",
    " \n",
    "def evaluate(attention_model,x_test,y_test):\n",
    "    \"\"\"\n",
    "        cv results\n",
    " \n",
    "        Args:\n",
    "            attention_model : {object} model\n",
    "            x_test          : {nplist} x_test\n",
    "            y_test          : {nplist} y_test\n",
    "       \n",
    "        Returns:\n",
    "            cv-accuracy\n",
    " \n",
    "      \n",
    "    \"\"\"\n",
    "   \n",
    "    attention_model.batch_size = x_test.shape[0]\n",
    "    attention_model.hidden_state = attention_model.init_hidden()\n",
    "    x_test_var = Variable(torch.from_numpy(x_test).type(torch.LongTensor))\n",
    "    y_test_pred,_ = attention_model(x_test_var)\n",
    "    if bool(attention_model.type):\n",
    "        y_preds = torch.max(y_test_pred,1)[1]\n",
    "        y_test_var = Variable(torch.from_numpy(y_test).type(torch.LongTensor))\n",
    "       \n",
    "    else:\n",
    "        y_preds = torch.round(y_test_pred.type(torch.DoubleTensor).squeeze(1))\n",
    "        y_test_var = Variable(torch.from_numpy(y_test).type(torch.DoubleTensor))\n",
    "       \n",
    "    return torch.eq(y_preds,y_test_var).data.sum()/x_test_var.size(0)\n",
    " \n",
    "def get_activation_wts(attention_model,x,seqlen):\n",
    "    \"\"\"\n",
    "        Get r attention heads\n",
    " \n",
    "        Args:\n",
    "            attention_model : {object} model\n",
    "            x               : {torch.Variable} input whose weights we want\n",
    "       \n",
    "        Returns:\n",
    "            r different attention weights\n",
    " \n",
    "      \n",
    "    \"\"\"\n",
    "    attention_model.batch_size = x.size(0)\n",
    "    attention_model.hidden_state = attention_model.init_hidden()\n",
    "    pred,wts = attention_model(x,seqlen)\n",
    "    print(pred.cpu().data.numpy())\n",
    "    return wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "def test(attention_model,test_loader,criterion):\n",
    "    \"\"\"\n",
    "        Training code\n",
    " \n",
    "        Args:\n",
    "            attention_model : {object} model\n",
    "            train_loader    : {DataLoader} training data loaded into a dataloader\n",
    "            optimizer       :  optimizer\n",
    "            criterion       :  loss function. Must be BCELoss for binary_classification and NLLLoss for multiclass\n",
    "            epochs          : {int} number of epochs\n",
    "            use_regularizer : {bool} use penalization or not\n",
    "            C               : {int} penalization coeff\n",
    "            clip            : {bool} use gradient clipping or not\n",
    "       \n",
    "        Returns:\n",
    "            accuracy and losses of the model\n",
    " \n",
    "      \n",
    "        \"\"\"\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "    print('test begin ...')\n",
    "    for i in range(1):\n",
    "#         print(\"Running EPOCH\",i+1)\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        correct = 0\n",
    "        recall = 0\n",
    "        AUC = 0\n",
    "        all_pred = np.array([0])\n",
    "        all_target = np.array([0])\n",
    "        totalpred = 0\n",
    "        for batch_idx,(lines, properties) in enumerate(test_loader):  \n",
    "            \n",
    "            input, seq_lengths, y = make_variables(lines, properties)\n",
    "            \n",
    "#              y = torch.DoubleTensor(y)\n",
    "            \n",
    "            attention_model.hidden_state = attention_model.init_hidden()\n",
    "\n",
    "            y_pred,att = attention_model(input,seq_lengths)\n",
    "#             print(y_pred.squeeze(1).size())\n",
    "#             print(y.size())\n",
    "           \n",
    "            #penalization AAT - I\n",
    "            if 1:\n",
    "                attT = att.transpose(1,2)\n",
    "                identity = torch.eye(att.size(1))\n",
    "                identity = Variable(identity.unsqueeze(0).expand(train_loader.batch_size,att.size(1),att.size(1))).cuda()\n",
    "                penal = attention_model.l2_matrix_norm(att@attT - identity)\n",
    "           \n",
    "            \n",
    "            if not bool(attention_model.type) :\n",
    "                #binary classification\n",
    "                #Adding a very small value to prevent BCELoss from outputting NaN's\n",
    "                pred = torch.round(y_pred.type(torch.DoubleTensor).squeeze(1))\n",
    "#                 print(pred)\n",
    "                totalpred = totalpred + pred.sum()\n",
    "#                 print(y)\n",
    "                correct+=torch.eq(torch.round(y_pred.type(torch.DoubleTensor).squeeze(1)),y.type(torch.DoubleTensor)).data.sum()\n",
    "                recall += metrics.recall_score(y.type(torch.DoubleTensor).data.numpy(), torch.round(y_pred.type(torch.DoubleTensor).squeeze(1)).data.numpy())\n",
    "                all_pred=np.concatenate((all_pred,y_pred.data.cpu().squeeze(1).numpy()),axis = 0)\n",
    "                all_target = np.concatenate((all_target,y.data.cpu().numpy()),axis = 0)\n",
    "                \n",
    "#                 print(recall)\n",
    "#                 print(correct.numpy()/(len(train_loader.dataset)))\n",
    "                \n",
    "                \n",
    "\n",
    "               \n",
    " \n",
    "#             total_loss+=loss.data\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "           \n",
    "            #gradient clipping\n",
    "#             if clip:\n",
    "#                 torch.nn.utils.clip_grad_norm(attention_model.parameters(),0.5)\n",
    "#             optimizer.step()\n",
    "            n_batches+=1\n",
    "        print(len(test_loader.dataset)) \n",
    "#         print(\"test_avg_loss is\",total_loss/n_batches)\n",
    "        print(\"Accuracy of the test set\",correct.numpy()/(n_batches*test_loader.batch_size))\n",
    "        print(\"recall =\",recall/n_batches)\n",
    "        \n",
    "        print(\"size = \",len(all_pred),len(all_target))\n",
    "        print(\"AUC = \",metrics.roc_auc_score(all_target, all_pred))\n",
    "#         losses.append(total_loss/n_batches)\n",
    "        accuracy.append(correct/(n_batches*train_loader.batch_size))\n",
    "    return losses,accuracy\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:79: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss is tensor(0.2411, dtype=torch.float64)\n",
      "Accuracy of the model 0.9088844355377421\n",
      "test begin ...\n",
      "1872\n",
      "Accuracy of the test set 0.9606681034482759\n",
      "recall = 0.8145138386517699\n",
      "size =  1857 1857\n",
      "AUC =  0.9729548623733744\n",
      "Running EPOCH 2\n",
      "avg_loss is tensor(1.00000e-02 *\n",
      "       7.4474, dtype=torch.float64)\n",
      "Accuracy of the model 0.9692718770875084\n",
      "test begin ...\n",
      "1872\n",
      "Accuracy of the test set 0.9870689655172413\n",
      "recall = 0.9565246056625367\n",
      "size =  1857 1857\n",
      "AUC =  0.9921434488656102\n",
      "Running EPOCH 3\n",
      "avg_loss is tensor(1.00000e-02 *\n",
      "       3.4611, dtype=torch.float64)\n",
      "Accuracy of the model 0.98249832999332\n",
      "test begin ...\n",
      "1872\n",
      "Accuracy of the test set 0.9892241379310345\n",
      "recall = 0.9535996570479328\n",
      "size =  1857 1857\n",
      "AUC =  0.9938923639797003\n",
      "Running EPOCH 4\n",
      "avg_loss is tensor(1.00000e-02 *\n",
      "       2.2617, dtype=torch.float64)\n",
      "Accuracy of the model 0.9857047428189712\n",
      "test begin ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872\n",
      "Accuracy of the test set 0.990301724137931\n",
      "recall = 0.939283226352192\n",
      "size =  1857 1857\n",
      "AUC =  0.9963568552201292\n",
      "Running EPOCH 5\n",
      "avg_loss is tensor(1.00000e-02 *\n",
      "       1.7105, dtype=torch.float64)\n",
      "Accuracy of the model 0.9861055444221777\n",
      "test begin ...\n",
      "1872\n",
      "Accuracy of the test set 0.9956896551724138\n",
      "recall = 0.9802681992337164\n",
      "size =  1857 1857\n",
      "AUC =  0.9968402304646846\n",
      "Running EPOCH 6\n",
      "avg_loss is tensor(1.00000e-03 *\n",
      "       9.7489, dtype=torch.float64)\n",
      "Accuracy of the model 0.9887775551102205\n",
      "test begin ...\n",
      "1872\n",
      "Accuracy of the test set 0.9935344827586207\n",
      "recall = 0.9840996168582377\n",
      "size =  1857 1857\n",
      "AUC =  0.9966848070839868\n",
      "Running EPOCH 7\n",
      "avg_loss is tensor(1.00000e-03 *\n",
      "       8.9902, dtype=torch.float64)\n",
      "Accuracy of the model 0.9894455577822311\n",
      "test begin ...\n",
      "1872\n",
      "Accuracy of the test set 0.9951508620689655\n",
      "recall = 0.9670087575259989\n",
      "size =  1857 1857\n",
      "AUC =  0.997638740805359\n",
      "Running EPOCH 8\n",
      "avg_loss is tensor(1.00000e-03 *\n",
      "       7.4606, dtype=torch.float64)\n",
      "Accuracy of the model 0.9898463593854375\n",
      "test begin ...\n",
      "1872\n",
      "Accuracy of the test set 0.9962284482758621\n",
      "recall = 0.9777777777777777\n",
      "size =  1857 1857\n",
      "AUC =  0.9975741225377748\n",
      "Running EPOCH 9\n",
      "avg_loss is tensor(1.00000e-03 *\n",
      "       9.1118, dtype=torch.float64)\n",
      "Accuracy of the model 0.9897127588510354\n",
      "test begin ...\n",
      "1872\n",
      "Accuracy of the test set 0.9978448275862069\n",
      "recall = 0.9912424740010948\n",
      "size =  1857 1857\n",
      "AUC =  0.9971784546363612\n",
      "Running EPOCH 10\n",
      "avg_loss is tensor(1.00000e-03 *\n",
      "       4.5494, dtype=torch.float64)\n",
      "Accuracy of the model 0.9911823647294589\n",
      "test begin ...\n",
      "1872\n",
      "Accuracy of the test set 0.9967672413793104\n",
      "recall = 0.9715106732348112\n",
      "size =  1857 1857\n",
      "AUC =  0.9961438764330188\n",
      "Running EPOCH 11\n",
      "avg_loss is tensor(1.00000e-03 *\n",
      "       8.9798, dtype=torch.float64)\n",
      "Accuracy of the model 0.9894455577822311\n",
      "test begin ...\n",
      "1872\n",
      "Accuracy of the test set 0.9956896551724138\n",
      "recall = 0.9777777777777777\n",
      "size =  1857 1857\n",
      "AUC =  0.9958590460189762\n",
      "Running EPOCH 12\n",
      "avg_loss is tensor(1.00000e-03 *\n",
      "       4.0413, dtype=torch.float64)\n",
      "Accuracy of the model 0.9911823647294589\n",
      "test begin ...\n",
      "1872\n",
      "Accuracy of the test set 0.9973060344827587\n",
      "recall = 0.9889730958696475\n",
      "size =  1857 1857\n",
      "AUC =  0.9952415694773773\n",
      "Running EPOCH 13\n",
      "avg_loss is tensor(1.00000e-03 *\n",
      "       4.5567, dtype=torch.float64)\n",
      "Accuracy of the model 0.9907815631262525\n",
      "test begin ...\n",
      "1872\n",
      "Accuracy of the test set 0.9962284482758621\n",
      "recall = 0.9908045977011495\n",
      "size =  1857 1857\n",
      "AUC =  0.996058362951284\n",
      "Running EPOCH 14\n",
      "avg_loss is tensor(1.00000e-03 *\n",
      "       4.1796, dtype=torch.float64)\n",
      "Accuracy of the model 0.9909151636606547\n",
      "test begin ...\n",
      "1872\n",
      "Accuracy of the test set 0.9956896551724138\n",
      "recall = 0.9657361795292829\n",
      "size =  1857 1857\n",
      "AUC =  0.9980964535340807\n",
      "Running EPOCH 15\n",
      "avg_loss is tensor(1.00000e-03 *\n",
      "       5.4942, dtype=torch.float64)\n",
      "Accuracy of the model 0.9910487641950568\n",
      "test begin ...\n",
      "1872\n",
      "Accuracy of the test set 0.9951508620689655\n",
      "recall = 0.9917898193760263\n",
      "size =  1857 1857\n",
      "AUC =  0.995780965612312\n"
     ]
    }
   ],
   "source": [
    "binary_classfication(attention_model,train_loader=train_loader,epochs=15,use_regularization=True,C=0.03,clip=True)\n",
    "\n",
    "classified = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 100])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch_idx,(lines, properties) in enumerate(train_loader):  \n",
    "        input, seq_lengths, y = make_variables(lines, properties)\n",
    "        if batch_idx>1: \n",
    "            break\n",
    "            \n",
    "input.size()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 19,  46,  23,  26,  23,  23,  25,  19,  15,  37,  23,  15,\n",
      "          23,  23,  37,  19,  19,   8,  37,  19,  19,   8,  25,  23,\n",
      "           6,  23,  23,  23,  23,  25,  32,  16,  23,   6,  16,  19,\n",
      "          25,  21,  46,  16,  19,  37,  16,  23,  23,  23,  26,  44,\n",
      "          23,  26,  23,  23,  23,  25,  19,  25,  33,  16,  25,  33,\n",
      "          16,  33,  16,  23,  23,  26],\n",
      "        [  8,  20,  19,  23,  26,  23,  23,  23,  37,  23,  23,  26,\n",
      "          46,  23,  26,  23,  23,  23,   6,  23,  23,  23,  23,  25,\n",
      "          23,   6,  23,  26,  16,  19,  25,  21,  46,  16,   8,  19,\n",
      "          19,   8,  19,  23,  26,  23,  29,  23,  15,  26,  19,  37,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0],\n",
      "        [ 46,  21,  19,  25,  23,  26,  23,  23,  23,  23,  37,  23,\n",
      "          23,  23,  23,  23,  26,  37,  16,   8,  26,  19,  19,   8,\n",
      "          25,  19,  23,  37,  23,  14,  23,  29,  37,  16,  23,  37,\n",
      "          23,  23,  23,  25,   1,  16,  23,  23,  37,  19,  26,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0],\n",
      "        [  8,  20,  19,  23,  26,  23,  23,  23,  25,  19,  15,  37,\n",
      "          23,  23,  15,  23,  37,  16,  23,  23,  26,  46,  23,  26,\n",
      "          23,  23,  23,  23,  25,  19,  25,  21,  46,  16,  23,  37,\n",
      "          23,  23,  23,  23,  23,  37,  16,  23,  26,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0],\n",
      "        [  8,  20,  19,  23,  26,  23,  23,  23,  25,  19,  15,  37,\n",
      "          23,  23,  29,  23,  37,  16,  23,  23,  26,  46,  23,  26,\n",
      "          23,  23,  23,  23,  25,   8,  23,  37,  23,  23,  23,  23,\n",
      "          23,  37,  16,  23,  26,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "            \n",
    "input, seq_lengths, _ = make_variables([\"O=C(c1cccc2ccccc12)N1CCN(Cc2c[nH]c[nH+]2)c2ccc(Br)cc2C1\",\n",
    "                                       \"COc1cc(Cn2cncc2CCN2CCN(c3cccc(Cl)c3)C(=O)C2)ccc1-c1ccc(C(F)(F)F)cc1\",\n",
    "                                       \"N#Cc1ccc(Cn2ccnc2)cc1Oc1cccc(C(=O)c2ccccc2)c1\",\n",
    "                                       \"N#Cc1ccc(Cn2cc[nH+]c2)cc1Oc1cccc(Nc2ccccc2)c1\",\n",
    "                                       \"N#Cc1ccc2cc1Oc1ccc3cccc(c3c1)C(=O)NCCNCc1c[nH+]cn1C2\"],[])\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_inactive, seq_lengths_inactive, _ = make_variables([\"O=C1CC(C(F)(F)F)N(C(=O)C[NH+]2CCC3CCCCC3C2)c2ccccc2N1\",\n",
    "                                       \"CCOC(=O)Cc1csc(NC(=O)CSC2[NH+]=c3ccc(C)cc3=[NH+]2)n1\",\n",
    "                                       \"O=C(CN1CCOC2CCCCC21)Nc1ccccc1S(=O)(=O)C(F)F\",\n",
    "                                       \"Cn1c(-c2ccccc2)nn(C[NH+]2CCC(c3ccccc3)CC2)c1=S\",\n",
    "                                       \"C=CCn1c(SCc2nc3ccsc3c(=O)[nH]2)nc2sccc2c1=O\"],[])\n",
    "print(input_inactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention(wts,x_test_pad,word_to_id,filename):\n",
    "    wts_add = torch.sum(wts,1)\n",
    "    wts_add_np = wts_add.cpu().data.numpy()\n",
    "    wts_add_list = wts_add_np.tolist()\n",
    "\n",
    "    text= []\n",
    "    print(x_test_pad)\n",
    "    for test in x_test_pad:\n",
    "        \n",
    "        text.append(\" \".join([id_to_word.get(i) for i in test]))\n",
    "        \n",
    "    print(text)\n",
    "    print(wts_add_list)\n",
    "    \n",
    "    createHTML(text, wts_add_list, filename)\n",
    "    print(\"Attention visualization created for {} samples\".format(len(x_test_pad)))\n",
    "    return wts_add_list,text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C', 'O', 'c', '1', 'c', 'c', '(', 'C', 'n', '2', 'c', 'n', 'c', 'c', '2', 'C', 'C', 'N', '2', 'C', 'C', 'N', '(', 'c', '3', 'c', 'c', 'c', 'c', '(', 'L', ')', 'c', '3', ')', 'C', '(', '=', 'O', ')', 'C', '2', ')', 'c', 'c', 'c', '1', '-', 'c', '1', 'c', 'c', 'c', '(', 'C', '(', 'F', ')', '(', 'F', ')', 'F', ')', 'c', 'c', '1'], ['N', '#', 'C', 'c', '1', 'c', 'c', 'c', '2', 'c', 'c', '1', 'O', 'c', '1', 'c', 'c', 'c', '3', 'c', 'c', 'c', 'c', '(', 'c', '3', 'c', '1', ')', 'C', '(', '=', 'O', ')', 'N', 'C', 'C', 'N', 'C', 'c', '1', 'c', '[nH+]', 'c', 'n', '1', 'C', '2', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['O', '=', 'C', '(', 'c', '1', 'c', 'c', 'c', 'c', '2', 'c', 'c', 'c', 'c', 'c', '1', '2', ')', 'N', '1', 'C', 'C', 'N', '(', 'C', 'c', '2', 'c', '[nH]', 'c', '[nH+]', '2', ')', 'c', '2', 'c', 'c', 'c', '(', 'R', ')', 'c', 'c', '2', 'C', '1', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['N', '#', 'C', 'c', '1', 'c', 'c', 'c', '(', 'C', 'n', '2', 'c', 'c', 'n', 'c', '2', ')', 'c', 'c', '1', 'O', 'c', '1', 'c', 'c', 'c', 'c', '(', 'C', '(', '=', 'O', ')', 'c', '2', 'c', 'c', 'c', 'c', 'c', '2', ')', 'c', '1', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['N', '#', 'C', 'c', '1', 'c', 'c', 'c', '(', 'C', 'n', '2', 'c', 'c', '[nH+]', 'c', '2', ')', 'c', 'c', '1', 'O', 'c', '1', 'c', 'c', 'c', 'c', '(', 'N', 'c', '2', 'c', 'c', 'c', 'c', 'c', '2', ')', 'c', '1', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']]\n"
     ]
    }
   ],
   "source": [
    "x_pad = input.cpu().data.numpy()\n",
    "text= []\n",
    "# print(x_test_pad)\n",
    "for test in x_pad:\n",
    "        text.append([id_to_word.get(i) for i in test]) \n",
    "\n",
    "#     text.append(\" \".join([id_to_word.get(i) for i in test]))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999297]\n",
      " [0.9999944 ]\n",
      " [0.9999949 ]\n",
      " [0.9999901 ]\n",
      " [0.99999344]]\n",
      "torch.Size([5, 20, 66])\n",
      "[[19 46 23 26 23 23 25 19 15 37 23 15 23 23 37 19 19  8 37 19 19  8 25 23\n",
      "   6 23 23 23 23 25 32 16 23  6 16 19 25 21 46 16 19 37 16 23 23 23 26 44\n",
      "  23 26 23 23 23 25 19 25 33 16 25 33 16 33 16 23 23 26]\n",
      " [ 8 20 19 23 26 23 23 23 37 23 23 26 46 23 26 23 23 23  6 23 23 23 23 25\n",
      "  23  6 23 26 16 19 25 21 46 16  8 19 19  8 19 23 26 23 29 23 15 26 19 37\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [46 21 19 25 23 26 23 23 23 23 37 23 23 23 23 23 26 37 16  8 26 19 19  8\n",
      "  25 19 23 37 23 14 23 29 37 16 23 37 23 23 23 25  1 16 23 23 37 19 26  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 8 20 19 23 26 23 23 23 25 19 15 37 23 23 15 23 37 16 23 23 26 46 23 26\n",
      "  23 23 23 23 25 19 25 21 46 16 23 37 23 23 23 23 23 37 16 23 26  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 8 20 19 23 26 23 23 23 25 19 15 37 23 23 29 23 37 16 23 23 26 46 23 26\n",
      "  23 23 23 23 25  8 23 37 23 23 23 23 23 37 16 23 26  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "['C O c 1 c c ( C n 2 c n c c 2 C C N 2 C C N ( c 3 c c c c ( L ) c 3 ) C ( = O ) C 2 ) c c c 1 - c 1 c c c ( C ( F ) ( F ) F ) c c 1', 'N # C c 1 c c c 2 c c 1 O c 1 c c c 3 c c c c ( c 3 c 1 ) C ( = O ) N C C N C c 1 c [nH+] c n 1 C 2 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>', 'O = C ( c 1 c c c c 2 c c c c c 1 2 ) N 1 C C N ( C c 2 c [nH] c [nH+] 2 ) c 2 c c c ( R ) c c 2 C 1 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>', 'N # C c 1 c c c ( C n 2 c c n c 2 ) c c 1 O c 1 c c c c ( C ( = O ) c 2 c c c c c 2 ) c 1 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>', 'N # C c 1 c c c ( C n 2 c c [nH+] c 2 ) c c 1 O c 1 c c c c ( N c 2 c c c c c 2 ) c 1 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>']\n",
      "[[0.005043381359428167, 0.005300058051943779, 0.0015607166569679976, 0.0021959547884762287, 0.0016238102689385414, 0.00139431853312999, 0.0013603958068415523, 0.0012884638272225857, 0.004663272760808468, 0.006323162466287613, 0.005130949430167675, 0.009123295545578003, 0.024630066007375717, 0.0893891379237175, 0.43551644682884216, 0.644359827041626, 0.6844028830528259, 0.7215529680252075, 0.714195966720581, 0.6767809391021729, 0.6868879199028015, 0.711209774017334, 0.7461861371994019, 0.7019740343093872, 0.7287198305130005, 0.667123556137085, 0.5824991464614868, 0.5851323008537292, 0.5505175590515137, 0.5506887435913086, 0.6742698550224304, 0.708945631980896, 0.5304720401763916, 0.6038761138916016, 0.6892597079277039, 0.56760573387146, 0.7042754292488098, 0.6371984481811523, 0.474720299243927, 0.4181380867958069, 0.178938090801239, 0.076700359582901, 0.034330666065216064, 0.035986416041851044, 0.028815295547246933, 0.0791090875864029, 0.3604113757610321, 0.5719221830368042, 0.3075076937675476, 0.518028736114502, 0.28460338711738586, 0.20527581870555878, 0.22959408164024353, 0.17603829503059387, 0.07923424243927002, 0.15013575553894043, 0.07404125481843948, 0.017610233277082443, 0.0171054694801569, 0.004600281827151775, 0.0016876538284122944, 0.0032433057203888893, 0.002554976614192128, 0.003318198723718524, 0.001552452682517469, 0.002119064098224044], [0.005224348045885563, 0.03236448019742966, 0.008249260485172272, 0.01708795502781868, 0.09947367012500763, 0.06649612635374069, 0.10831747949123383, 0.1307983100414276, 0.4322563409805298, 0.1480865180492401, 0.10103293508291245, 0.5328655242919922, 0.5187386274337769, 0.20941320061683655, 0.38477131724357605, 0.1392439752817154, 0.1187351793050766, 0.1618877351284027, 0.3232186436653137, 0.20538926124572754, 0.13369782269001007, 0.15781979262828827, 0.152507483959198, 0.08457125723361969, 0.09217317402362823, 0.08095551282167435, 0.04576382040977478, 0.15039676427841187, 0.16378013789653778, 0.020273778587579727, 0.06596074998378754, 0.012305893003940582, 0.0037013532128185034, 0.002684428356587887, 0.0028421743772923946, 0.0015335421776399016, 0.0012059260625392199, 0.0012112006079405546, 0.0011997886467725039, 0.0013144873082637787, 0.0015337516088038683, 0.0014145681634545326, 0.04281162470579147, 0.03171586990356445, 0.16526903212070465, 0.7679378986358643, 0.7555199861526489, 0.7750272750854492, 0.7857778668403625, 0.8012731671333313, 0.8003019094467163, 0.797524094581604, 0.7936657071113586, 0.7883968949317932, 0.7816479206085205, 0.7731903195381165, 0.7623986601829529, 0.7488998770713806, 0.732640266418457, 0.7127138376235962, 0.6857806444168091, 0.6452094316482544, 0.5890867710113525, 0.5241191387176514, 0.4505584239959717, 0.3660351634025574], [0.008821148425340652, 0.008749881759285927, 0.021122358739376068, 0.029493393376469612, 0.006082796026021242, 0.005787719506770372, 0.003202896099537611, 0.0016217203810811043, 0.0016910656122490764, 0.0018261109944432974, 0.004380334634333849, 0.0019043823704123497, 0.0018476226832717657, 0.002027881797403097, 0.0020585842430591583, 0.00208670599386096, 0.008542818948626518, 0.004658110439777374, 0.008365985006093979, 0.0053382329642772675, 0.005415969528257847, 0.001499326666817069, 0.0009819341357797384, 0.0010042842477560043, 0.001031403779052198, 0.0010536997579038143, 0.0010910669807344675, 0.0015491577796638012, 0.0018377213273197412, 0.0430176742374897, 0.024884574115276337, 0.5991380214691162, 0.6778312921524048, 0.760313868522644, 0.6994121074676514, 0.7008353471755981, 0.6387253403663635, 0.5573148727416992, 0.5988833904266357, 0.6166066527366638, 0.6809467077255249, 0.7252750396728516, 0.6232616901397705, 0.5539893507957458, 0.6881240010261536, 0.6500736474990845, 0.7215619087219238, 0.7192018032073975, 0.7218505144119263, 0.7171834707260132, 0.7099529504776001, 0.7001848220825195, 0.6878165006637573, 0.672569215297699, 0.654313325881958, 0.632509708404541, 0.604433000087738, 0.5592620968818665, 0.4869416058063507, 0.4078093469142914, 0.3299751877784729, 0.2577635645866394, 0.18931199610233307, 0.1253977119922638, 0.07642906159162521, 0.041824690997600555], [0.00557719636708498, 0.03473951667547226, 0.008806522935628891, 0.01816590316593647, 0.10688101500272751, 0.07088498771190643, 0.1155153214931488, 0.1395251452922821, 0.08187199383974075, 0.03456301987171173, 0.1265871226787567, 0.15425357222557068, 0.06331568956375122, 0.1263679414987564, 0.17127877473831177, 0.5499731302261353, 0.6826383471488953, 0.8721709251403809, 0.7569829225540161, 0.6668972969055176, 0.854762077331543, 0.8672083616256714, 0.7376953363418579, 0.8162563443183899, 0.6811835169792175, 0.563194751739502, 0.5705372095108032, 0.5351197123527527, 0.541534960269928, 0.4335572123527527, 0.616560697555542, 0.5289677381515503, 0.23689711093902588, 0.2650090456008911, 0.10530887544155121, 0.03916298598051071, 0.017514538019895554, 0.03353147953748703, 0.10149840265512466, 0.17507117986679077, 0.2063065767288208, 0.4931575357913971, 0.7178720831871033, 0.4260854125022888, 0.6438592672348022, 0.666153609752655, 0.645520806312561, 0.6011029481887817, 0.550150990486145, 0.48532634973526, 0.38530948758125305, 0.2713674306869507, 0.17724376916885376, 0.10279721021652222, 0.05309383198618889, 0.025872603058815002, 0.013452127575874329, 0.007907363586127758, 0.004908261355012655, 0.0032295917626470327, 0.0023662536405026913, 0.001990447286516428, 0.0018547989893704653, 0.001818163087591529, 0.0018142692279070616, 0.0018708084244281054], [0.004754986613988876, 0.029586194083094597, 0.007509925402700901, 0.015496318228542805, 0.09102363884449005, 0.06043180078268051, 0.09847205877304077, 0.11893036961555481, 0.06974968314170837, 0.02948313020169735, 0.10778564214706421, 0.131272554397583, 0.053939901292324066, 0.10766607522964478, 0.6460171937942505, 0.5530147552490234, 0.6430183053016663, 0.7443966269493103, 0.6597983837127686, 0.5899049043655396, 0.7233757972717285, 0.7372370958328247, 0.6381314992904663, 0.6947277784347534, 0.5971357822418213, 0.502538800239563, 0.5043879747390747, 0.4713725447654724, 0.47281980514526367, 0.5476264953613281, 0.3866167366504669, 0.5359618663787842, 0.33778470754623413, 0.2677501440048218, 0.3200528621673584, 0.3170839250087738, 0.30329862236976624, 0.5306742191314697, 0.6538724899291992, 0.44851475954055786, 0.5978670120239258, 0.6096321940422058, 0.5971698760986328, 0.5668683052062988, 0.5330808162689209, 0.4954528510570526, 0.45382872223854065, 0.40171897411346436, 0.3205075263977051, 0.2377128005027771, 0.16568773984909058, 0.10601817071437836, 0.0633733868598938, 0.03662283718585968, 0.02111799456179142, 0.012603946961462498, 0.007455606944859028, 0.004767796956002712, 0.00324810016900301, 0.0022662950213998556, 0.0018140769097954035, 0.0016473925206810236, 0.0015870421193540096, 0.0015585438814014196, 0.0015635932795703411, 0.001611828338354826]]\n",
      "Attention visualization created for 5 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "if classified:\n",
    "#     test_last_idx = 100\n",
    "    wts = get_activation_wts(attention_model,input,seq_lengths)\n",
    "    print(wts.size())\n",
    "    x_pad = input.cpu().data.numpy()\n",
    "    \n",
    "    add_weight,smiles = visualize_attention(wts,x_pad,word_to_id,filename='pharmacophore4.html')\n",
    "#     print(wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word.get(38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_weight = dict(zip(text[0],add_weight[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 4, 5, 7, 8, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 23, 25, 26, 27, 28, 30, 32, 35, 38, 40, 43, 44, 45, 48, 50, 51, 52, 54, 56, 59, 61, 63, 64]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlight=[]\n",
    "for index,token in enumerate(text[0]):\n",
    "    for j in atom_set:        \n",
    "        if j in token:            \n",
    "            highlight.append(index)\n",
    "            break\n",
    "    \n",
    "\n",
    "print(highlight)\n",
    "len(highlight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.005043381359428167, 0.005300058051943779, 0.0015607166569679976, 0.0016238102689385414, 0.00139431853312999, 0.0012884638272225857, 0.004663272760808468, 0.005130949430167675, 0.009123295545578003, 0.024630066007375717, 0.0893891379237175, 0.644359827041626, 0.6844028830528259, 0.7215529680252075, 0.6767809391021729, 0.6868879199028015, 0.711209774017334, 0.7019740343093872, 0.667123556137085, 0.5824991464614868, 0.5851323008537292, 0.5505175590515137, 0.6742698550224304, 0.5304720401763916, 0.56760573387146, 0.474720299243927, 0.178938090801239, 0.035986416041851044, 0.028815295547246933, 0.0791090875864029, 0.3075076937675476, 0.28460338711738586, 0.20527581870555878, 0.22959408164024353, 0.07923424243927002, 0.07404125481843948, 0.004600281827151775, 0.0032433057203888893, 0.003318198723718524, 0.001552452682517469]\n"
     ]
    }
   ],
   "source": [
    "atomWeight = []\n",
    "for atom_index in highlight:\n",
    "    atomWeight.append(add_weight[0][atom_index])\n",
    "    \n",
    "print(atomWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "max_num_index_list = map(add_weight[0].index, heapq.nlargest(15, add_weight[0]))\n",
    "maxlist = list(max_num_index_list)\n",
    "print(maxlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.005043381359428167,\n",
       " 0.005300058051943779,\n",
       " 0.0015607166569679976,\n",
       " 0.0021959547884762287,\n",
       " 0.0016238102689385414,\n",
       " 0.00139431853312999,\n",
       " 0.0013603958068415523,\n",
       " 0.0012884638272225857,\n",
       " 0.004663272760808468,\n",
       " 0.006323162466287613,\n",
       " 0.005130949430167675,\n",
       " 0.009123295545578003,\n",
       " 0.024630066007375717,\n",
       " 0.0893891379237175,\n",
       " 0.43551644682884216,\n",
       " 0.644359827041626,\n",
       " 0.6844028830528259,\n",
       " 0.7215529680252075,\n",
       " 0.714195966720581,\n",
       " 0.6767809391021729,\n",
       " 0.6868879199028015,\n",
       " 0.711209774017334,\n",
       " 0.7461861371994019,\n",
       " 0.7019740343093872,\n",
       " 0.7287198305130005,\n",
       " 0.667123556137085,\n",
       " 0.5824991464614868,\n",
       " 0.5851323008537292,\n",
       " 0.5505175590515137,\n",
       " 0.5506887435913086,\n",
       " 0.6742698550224304,\n",
       " 0.708945631980896,\n",
       " 0.5304720401763916,\n",
       " 0.6038761138916016,\n",
       " 0.6892597079277039,\n",
       " 0.56760573387146,\n",
       " 0.7042754292488098,\n",
       " 0.6371984481811523,\n",
       " 0.474720299243927,\n",
       " 0.4181380867958069,\n",
       " 0.178938090801239,\n",
       " 0.076700359582901,\n",
       " 0.034330666065216064,\n",
       " 0.035986416041851044,\n",
       " 0.028815295547246933,\n",
       " 0.0791090875864029,\n",
       " 0.3604113757610321,\n",
       " 0.5719221830368042,\n",
       " 0.3075076937675476,\n",
       " 0.518028736114502,\n",
       " 0.28460338711738586,\n",
       " 0.20527581870555878,\n",
       " 0.22959408164024353,\n",
       " 0.17603829503059387,\n",
       " 0.07923424243927002,\n",
       " 0.15013575553894043,\n",
       " 0.07404125481843948,\n",
       " 0.017610233277082443,\n",
       " 0.0171054694801569,\n",
       " 0.004600281827151775,\n",
       " 0.0016876538284122944,\n",
       " 0.0032433057203888893,\n",
       " 0.002554976614192128,\n",
       " 0.003318198723718524,\n",
       " 0.001552452682517469,\n",
       " 0.002119064098224044]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C', 'O', 'c', '1', 'c', 'c', '(', 'C', 'n', '2', 'c', 'n', 'c', 'c', '2', 'C', 'C', 'N', '2', 'C', 'C', 'N', '(', 'c', '3', 'c', 'c', 'c', 'c', '(', 'L', ')', 'c', '3', ')', 'C', '(', '=', 'O', ')', 'C', '2', ')', 'c', 'c', 'c', '1', '-', 'c', '1', 'c', 'c', 'c', '(', 'C', '(', 'F', ')', '(', 'F', ')', 'F', ')', 'c', 'c', '1'], ['N', '#', 'C', 'c', '1', 'c', 'c', 'c', '2', 'c', 'c', '1', 'O', 'c', '1', 'c', 'c', 'c', '3', 'c', 'c', 'c', 'c', '(', 'c', '3', 'c', '1', ')', 'C', '(', '=', 'O', ')', 'N', 'C', 'C', 'N', 'C', 'c', '1', 'c', '[nH+]', 'c', 'n', '1', 'C', '2', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['O', '=', 'C', '(', 'c', '1', 'c', 'c', 'c', 'c', '2', 'c', 'c', 'c', 'c', 'c', '1', '2', ')', 'N', '1', 'C', 'C', 'N', '(', 'C', 'c', '2', 'c', '[nH]', 'c', '[nH+]', '2', ')', 'c', '2', 'c', 'c', 'c', '(', 'R', ')', 'c', 'c', '2', 'C', '1', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['N', '#', 'C', 'c', '1', 'c', 'c', 'c', '(', 'C', 'n', '2', 'c', 'c', 'n', 'c', '2', ')', 'c', 'c', '1', 'O', 'c', '1', 'c', 'c', 'c', 'c', '(', 'C', '(', '=', 'O', ')', 'c', '2', 'c', 'c', 'c', 'c', 'c', '2', ')', 'c', '1', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['N', '#', 'C', 'c', '1', 'c', 'c', 'c', '(', 'C', 'n', '2', 'c', 'c', '[nH+]', 'c', '2', ')', 'c', 'c', '1', 'O', 'c', '1', 'c', 'c', 'c', 'c', '(', 'N', 'c', '2', 'c', 'c', 'c', 'c', 'c', '2', ')', 'c', '1', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']]\n",
      "[22, 24, 17, 18, 21, 31, 36, 23, 34, 20, 16, 19, 30, 25, 15]\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "import heapq\n",
    "max_num_index_list = map(add_weight[0].index, heapq.nlargest(15, add_weight[0]))\n",
    "maxlist = list(max_num_index_list)\n",
    "print(maxlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'N', 'c', 'C', 'C', 'C', 'L', 'c', 'C']\n"
     ]
    }
   ],
   "source": [
    "highlight=[]\n",
    "for i in range(15):\n",
    "    for j in atom_set:        \n",
    "        if j in text[0][maxlist[i]]:\n",
    "            highlight.append(text[0][maxlist[i]])\n",
    "            break\n",
    "    \n",
    "\n",
    "print(highlight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_set = ['c','C','o','O','n','N','L','R','I','P','S','s','P','F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(add_weight[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-e18bcd30a8f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_to_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "text = []\n",
    "b =input.squeeze(1).data.numpy()\n",
    "for test in b:\n",
    "    text.append(\" \".join([id_to_word.get(test)]))\n",
    "    \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_word.get(add_weight[0][36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'O', 'C', '(', '=', 'O', ')', '[C@H]', '1', 'O', 'C', '2', '=', 'C', '(', '[C@H]', '1', 'c', '3', 'c', 'c', 'c', 'n', 'c', '3', ')', 'C', '(', '=', 'O', ')', 'O', 'c', '4', 'c', 'c', 'c', 'c', 'c', '2', '4']\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "\n",
    "for test in b:\n",
    "    text.append(\" \".join([id_to_word.get(test)]))\n",
    "    \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
